{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e82edb3-3c90-4a1b-bb81-5bea4e6d8ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sum([1, 2, 3]) == 6, \"Should be 6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81f5d175-f49c-483c-8e5e-61e8ab929c06",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Should be 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28msum\u001b[39m([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be 6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Should be 6"
     ]
    }
   ],
   "source": [
    "assert sum([1, 1, 1]) == 6, \"Should be 6\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f0eda29-6947-4f97-a811-0a91a0b87c89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything passed\n"
     ]
    }
   ],
   "source": [
    "# %load test_sum.py\n",
    "def test_sum():\n",
    "    assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_sum()\n",
    "    print(\"Everything passed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "189e2a21-cf36-47d6-a649-dff85503a581",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Should be 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m      9\u001b[0m     test_sum()\n\u001b[1;32m---> 10\u001b[0m     test_sum_tuple()\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEverything passed\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[12], line 6\u001b[0m, in \u001b[0;36mtest_sum_tuple\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtest_sum_tuple\u001b[39m():\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28msum\u001b[39m((\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m)) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m6\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould be 6\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Should be 6"
     ]
    }
   ],
   "source": [
    "# %load test_sum_2.py\n",
    "def test_sum():\n",
    "    assert sum([1, 2, 3]) == 6, \"Should be 6\"\n",
    "\n",
    "def test_sum_tuple():\n",
    "    assert sum((1, 2, 2)) == 6, \"Should be 6\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    test_sum()\n",
    "    test_sum_tuple()\n",
    "    print(\"Everything passed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fa8492-e35f-4248-9616-5d6a223e9876",
   "metadata": {},
   "source": [
    "For the examples above the results:\n",
    "The first test passed, we know this because we did not get raised assertion failure. \n",
    "However, the second test failed because 1+1+1 is not six, this raised assertion failure. \n",
    "Then we see that for test_sum.py, the print statement printed, indicating it passed. This is different than the first test with the lack of print statement or confirmation of passing. \n",
    "With test_sum_2, the test runs and we see an error since everthing did not pass.\n",
    "\n",
    "For the unittest in VS Code:\n",
    "\n",
    "For the first unit test, I ran the test.py file with the unittest runner, it passed. It ran the single test in the file and summarized the results which was that the test passed, this is indicated by the word \"ok.\" \n",
    "\n",
    "For the second unit test, I ran the test.py file with the unittest runner utilzing the verbose option, -v, which gives us some more information about each test that was run. This also gave us the \"ok.\" This means it passed as expected! \n",
    "\n",
    "For the third unit test, I ran the \"unittest discover\" runner to look for files beginging with \"test\" in a directory and ending in \".py\" Additionally, I used the -s flag with test as the value which looks for those files in a directory named test. This failed because I have no test directory. \n",
    "\n",
    "The fourth test including adding an additional test called test_list_fraction. This one failed. That was shown in the output of the unittest runner. It ran 2 tests and states that theres one failure and states that the failure is due to line 22. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
